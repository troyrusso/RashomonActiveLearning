{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fc10f51",
   "metadata": {},
   "source": [
    "# [BatchBALD](https://blackhc.github.io/batchbald_redux/batchbald.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a42c43",
   "metadata": {},
   "source": [
    "BALD creates $K$ plausible parameter settings under the posterior distribution and generates $K$ prediction probabilities from these different parameter settings. Instead of training seperate models, BALD samples the distribution of possible models given the data.\n",
    "\n",
    "Each parameter setting in BALD then produces a probability distribution over the classes. We then measure the\n",
    "1. Marginal Entropy $H(y|x,D)$: \n",
    "    - Measures the overall uncertainty about the class of data point $x$, considering all the different probability distributions from all the \"models.\" \n",
    "    - This tells us how uncertain the ensemble is in general.\n",
    "2. Expected Conditinoal Entropy $E_{\\theta\\sim p(\\theta|D)}\\big[H(y|x,\\theta)\\big]$: \n",
    "    - Measures the average uncertainity of each individual model with parameter setting $\\theta$ that follows from posterior distribution $p(\\theta|D)$. \n",
    "    - It tells us how certain an individual model is.\n",
    "We then integrate over all possible parameter settings $\\theta$\n",
    "$$\n",
    "E_{\\theta \\sim p(\\theta | \\mathcal{D})} [H[y|x, \\theta]] = \\int p(\\theta | \\mathcal{D}) H[y|x, \\theta] d\\theta\n",
    "$$\n",
    "\n",
    "The selection criteria is then given by\n",
    "\n",
    "$$ \n",
    "\\arg \\max_x H(y|x,D) - E_{\\theta \\sim p(\\theta|D)}\\big[H(y|x,\\theta)\\big]\n",
    "$$\n",
    "\n",
    "This can be viewed as the difference between the uncertainty of the entire ensemble minus the certainty of a single model. As such, BALD is looking for an $x$ where the ensemble is very uncertain, but the individual models are certain. That is, finding the $x$ where the parameters under the posterior distribution disagree about the outcome the most, but the ensemble is still certain.\n",
    "\n",
    "This selection criteria captures the difference in disagreements among the plausible model configurations.\n",
    "\n",
    "**I bet there can be some connection to Rashomon here regarding the fact that BALD *samples* the plausible parameter settings from the posterior but TreeFarms exhaustively generates all trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d4624",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "978e4187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simondn/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from toma import toma\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from batchbald_redux import joint_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a38a6a8",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36533f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70847e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/10/2lfzfs1j0j933_mjkrskp5kh0000gq/T/ipykernel_20301/4233380681.py:30: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:257.)\n",
      "  return torch.stack(list(map(torch.as_tensor, l)))\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def get_mixture_prob_dist(p1, p2, m):\n",
    "#     return (1.0 - m) * np.asarray(p1) + m * np.asarray(p2)\n",
    "\n",
    "\n",
    "# p1 = [0.7, 0.1, 0.1, 0.1]\n",
    "# p2 = [0.3, 0.3, 0.2, 0.2]\n",
    "# y1_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "# p1 = [0.1, 0.7, 0.1, 0.1]\n",
    "# p2 = [0.2, 0.3, 0.3, 0.2]\n",
    "# y2_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "# p1 = [0.1, 0.1, 0.7, 0.1]\n",
    "# p2 = [0.2, 0.2, 0.3, 0.3]\n",
    "# y3_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "# p1 = [0.1, 0.1, 0.1, 0.7]\n",
    "# p2 = [0.3, 0.2, 0.2, 0.3]\n",
    "# y4_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "# p1 = [0.2, 0.3, 0.4, 0.1]\n",
    "# p2 = [0.1, 0.4, 0.3, 0.2]\n",
    "# y5_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "\n",
    "# def nested_to_tensor(l):\n",
    "#     return torch.stack(list(map(torch.as_tensor, l)))\n",
    "\n",
    "\n",
    "# ys_ws = nested_to_tensor([y1_ws, y2_ws, y3_ws, y4_ws, y5_ws])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85b4014c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 20, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_ws.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6cb8832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7000, 0.1000, 0.1000, 0.1000],\n",
       "         [0.6789, 0.1105, 0.1053, 0.1053],\n",
       "         [0.6579, 0.1211, 0.1105, 0.1105],\n",
       "         [0.6368, 0.1316, 0.1158, 0.1158],\n",
       "         [0.6158, 0.1421, 0.1211, 0.1211],\n",
       "         [0.5947, 0.1526, 0.1263, 0.1263],\n",
       "         [0.5737, 0.1632, 0.1316, 0.1316],\n",
       "         [0.5526, 0.1737, 0.1368, 0.1368],\n",
       "         [0.5316, 0.1842, 0.1421, 0.1421],\n",
       "         [0.5105, 0.1947, 0.1474, 0.1474],\n",
       "         [0.4895, 0.2053, 0.1526, 0.1526],\n",
       "         [0.4684, 0.2158, 0.1579, 0.1579],\n",
       "         [0.4474, 0.2263, 0.1632, 0.1632],\n",
       "         [0.4263, 0.2368, 0.1684, 0.1684],\n",
       "         [0.4053, 0.2474, 0.1737, 0.1737],\n",
       "         [0.3842, 0.2579, 0.1789, 0.1789],\n",
       "         [0.3632, 0.2684, 0.1842, 0.1842],\n",
       "         [0.3421, 0.2789, 0.1895, 0.1895],\n",
       "         [0.3211, 0.2895, 0.1947, 0.1947],\n",
       "         [0.3000, 0.3000, 0.2000, 0.2000]],\n",
       "\n",
       "        [[0.1000, 0.7000, 0.1000, 0.1000],\n",
       "         [0.1053, 0.6789, 0.1105, 0.1053],\n",
       "         [0.1105, 0.6579, 0.1211, 0.1105],\n",
       "         [0.1158, 0.6368, 0.1316, 0.1158],\n",
       "         [0.1211, 0.6158, 0.1421, 0.1211],\n",
       "         [0.1263, 0.5947, 0.1526, 0.1263],\n",
       "         [0.1316, 0.5737, 0.1632, 0.1316],\n",
       "         [0.1368, 0.5526, 0.1737, 0.1368],\n",
       "         [0.1421, 0.5316, 0.1842, 0.1421],\n",
       "         [0.1474, 0.5105, 0.1947, 0.1474],\n",
       "         [0.1526, 0.4895, 0.2053, 0.1526],\n",
       "         [0.1579, 0.4684, 0.2158, 0.1579],\n",
       "         [0.1632, 0.4474, 0.2263, 0.1632],\n",
       "         [0.1684, 0.4263, 0.2368, 0.1684],\n",
       "         [0.1737, 0.4053, 0.2474, 0.1737],\n",
       "         [0.1789, 0.3842, 0.2579, 0.1789],\n",
       "         [0.1842, 0.3632, 0.2684, 0.1842],\n",
       "         [0.1895, 0.3421, 0.2789, 0.1895],\n",
       "         [0.1947, 0.3211, 0.2895, 0.1947],\n",
       "         [0.2000, 0.3000, 0.3000, 0.2000]],\n",
       "\n",
       "        [[0.1000, 0.1000, 0.7000, 0.1000],\n",
       "         [0.1053, 0.1053, 0.6789, 0.1105],\n",
       "         [0.1105, 0.1105, 0.6579, 0.1211],\n",
       "         [0.1158, 0.1158, 0.6368, 0.1316],\n",
       "         [0.1211, 0.1211, 0.6158, 0.1421],\n",
       "         [0.1263, 0.1263, 0.5947, 0.1526],\n",
       "         [0.1316, 0.1316, 0.5737, 0.1632],\n",
       "         [0.1368, 0.1368, 0.5526, 0.1737],\n",
       "         [0.1421, 0.1421, 0.5316, 0.1842],\n",
       "         [0.1474, 0.1474, 0.5105, 0.1947],\n",
       "         [0.1526, 0.1526, 0.4895, 0.2053],\n",
       "         [0.1579, 0.1579, 0.4684, 0.2158],\n",
       "         [0.1632, 0.1632, 0.4474, 0.2263],\n",
       "         [0.1684, 0.1684, 0.4263, 0.2368],\n",
       "         [0.1737, 0.1737, 0.4053, 0.2474],\n",
       "         [0.1789, 0.1789, 0.3842, 0.2579],\n",
       "         [0.1842, 0.1842, 0.3632, 0.2684],\n",
       "         [0.1895, 0.1895, 0.3421, 0.2789],\n",
       "         [0.1947, 0.1947, 0.3211, 0.2895],\n",
       "         [0.2000, 0.2000, 0.3000, 0.3000]],\n",
       "\n",
       "        [[0.1000, 0.1000, 0.1000, 0.7000],\n",
       "         [0.1105, 0.1053, 0.1053, 0.6789],\n",
       "         [0.1211, 0.1105, 0.1105, 0.6579],\n",
       "         [0.1316, 0.1158, 0.1158, 0.6368],\n",
       "         [0.1421, 0.1211, 0.1211, 0.6158],\n",
       "         [0.1526, 0.1263, 0.1263, 0.5947],\n",
       "         [0.1632, 0.1316, 0.1316, 0.5737],\n",
       "         [0.1737, 0.1368, 0.1368, 0.5526],\n",
       "         [0.1842, 0.1421, 0.1421, 0.5316],\n",
       "         [0.1947, 0.1474, 0.1474, 0.5105],\n",
       "         [0.2053, 0.1526, 0.1526, 0.4895],\n",
       "         [0.2158, 0.1579, 0.1579, 0.4684],\n",
       "         [0.2263, 0.1632, 0.1632, 0.4474],\n",
       "         [0.2368, 0.1684, 0.1684, 0.4263],\n",
       "         [0.2474, 0.1737, 0.1737, 0.4053],\n",
       "         [0.2579, 0.1789, 0.1789, 0.3842],\n",
       "         [0.2684, 0.1842, 0.1842, 0.3632],\n",
       "         [0.2789, 0.1895, 0.1895, 0.3421],\n",
       "         [0.2895, 0.1947, 0.1947, 0.3211],\n",
       "         [0.3000, 0.2000, 0.2000, 0.3000]],\n",
       "\n",
       "        [[0.2000, 0.3000, 0.4000, 0.1000],\n",
       "         [0.1947, 0.3053, 0.3947, 0.1053],\n",
       "         [0.1895, 0.3105, 0.3895, 0.1105],\n",
       "         [0.1842, 0.3158, 0.3842, 0.1158],\n",
       "         [0.1789, 0.3211, 0.3789, 0.1211],\n",
       "         [0.1737, 0.3263, 0.3737, 0.1263],\n",
       "         [0.1684, 0.3316, 0.3684, 0.1316],\n",
       "         [0.1632, 0.3368, 0.3632, 0.1368],\n",
       "         [0.1579, 0.3421, 0.3579, 0.1421],\n",
       "         [0.1526, 0.3474, 0.3526, 0.1474],\n",
       "         [0.1474, 0.3526, 0.3474, 0.1526],\n",
       "         [0.1421, 0.3579, 0.3421, 0.1579],\n",
       "         [0.1368, 0.3632, 0.3368, 0.1632],\n",
       "         [0.1316, 0.3684, 0.3316, 0.1684],\n",
       "         [0.1263, 0.3737, 0.3263, 0.1737],\n",
       "         [0.1211, 0.3789, 0.3211, 0.1789],\n",
       "         [0.1158, 0.3842, 0.3158, 0.1842],\n",
       "         [0.1105, 0.3895, 0.3105, 0.1895],\n",
       "         [0.1053, 0.3947, 0.3053, 0.1947],\n",
       "         [0.1000, 0.4000, 0.3000, 0.2000]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_ws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d333bc",
   "metadata": {},
   "source": [
    "## Conditional Entropies and Batched Entropies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bf29365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeConditionalEntropyFunction(log_probs_N_K_C: torch.Tensor) -> torch.Tensor:\n",
    "    \n",
    "    ### Set Up ###\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "    entropies_N = torch.empty(N, dtype=torch.double)\n",
    "    pbar = tqdm(total=N, desc=\"Conditional Entropy\", leave=False)\n",
    "\n",
    "\n",
    "    ### Compute entropy ###\n",
    "    @toma.execute.chunked(log_probs_N_K_C, 1024)\n",
    "    def compute(log_probs_n_K_C, start: int, end: int):\n",
    "        EntropyVals = log_probs_n_K_C * torch.exp(log_probs_n_K_C)\n",
    "        entropies_N[start:end].copy_(-torch.sum(EntropyVals, dim=(1, 2)) / K)\n",
    "        pbar.update(end - start)\n",
    "    pbar.close()\n",
    "\n",
    "    ### Return ###\n",
    "    return entropies_N\n",
    "\n",
    "\n",
    "def ComputeEntropyFunction(log_probs_N_K_C: torch.Tensor) -> torch.Tensor:\n",
    "    \n",
    "    ### Set Up ###\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "    entropies_N = torch.empty(N, dtype=torch.double)\n",
    "    pbar = tqdm(total=N, desc=\"Entropy\", leave=False)\n",
    "\n",
    "    ### Compute entropy ###\n",
    "    @toma.execute.chunked(log_probs_N_K_C, 1024)\n",
    "    def compute(log_probs_n_K_C, start: int, end: int):\n",
    "        mean_log_probs_n_C = torch.logsumexp(log_probs_n_K_C, dim=1) - math.log(K)\n",
    "        nats_n_C = mean_log_probs_n_C * torch.exp(mean_log_probs_n_C)\n",
    "        entropies_N[start:end].copy_(-torch.sum(nats_n_C, dim=1))\n",
    "        pbar.update(end - start)\n",
    "\n",
    "    ### Return ###\n",
    "    pbar.close()\n",
    "\n",
    "    return entropies_N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6f1eea",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e79855d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Conditional Entropy:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2069, 1.2069, 1.2069, 1.2069, 1.2952], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "conditional_entropies = ComputeConditionalEntropyFunction(ys_ws.log())\n",
    "\n",
    "print(conditional_entropies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d4d7cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2376, 1.2376, 1.2376, 1.2376, 1.3040], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "entropies = ComputeEntropyFunction(ys_ws.log())\n",
    "\n",
    "print(entropies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a457c596",
   "metadata": {},
   "source": [
    "## BALD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e269420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CandidateBatch:\n",
    "    scores: List[float]\n",
    "    indices: List[int]\n",
    "\n",
    "\n",
    "def get_batchbald_batch(\n",
    "    log_probs_N_K_C: torch.Tensor, batch_size: int, num_samples: int, dtype=None, device=None\n",
    ") -> CandidateBatch:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_indices = []\n",
    "    candidate_scores = []\n",
    "\n",
    "    if batch_size == 0:\n",
    "        return CandidateBatch(candidate_scores, candidate_indices)\n",
    "\n",
    "    conditional_entropies_N = ComputeConditionalEntropyFunction(log_probs_N_K_C)\n",
    "\n",
    "    batch_joint_entropy = joint_entropy.DynamicJointEntropy(\n",
    "        num_samples, batch_size - 1, K, C, dtype=dtype, device=device\n",
    "    )\n",
    "\n",
    "    # We always keep these on the CPU.\n",
    "    scores_N = torch.empty(N, dtype=torch.double, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "    for i in tqdm(range(batch_size), desc=\"BatchBALD\", leave=False):\n",
    "        if i > 0:\n",
    "            latest_index = candidate_indices[-1]\n",
    "            batch_joint_entropy.add_variables(log_probs_N_K_C[latest_index : latest_index + 1])\n",
    "\n",
    "        shared_conditinal_entropies = conditional_entropies_N[candidate_indices].sum()\n",
    "\n",
    "        batch_joint_entropy.compute_batch(log_probs_N_K_C, output_entropies_B=scores_N)\n",
    "\n",
    "        scores_N -= conditional_entropies_N + shared_conditinal_entropies\n",
    "        scores_N[candidate_indices] = -float(\"inf\")\n",
    "\n",
    "        candidate_score, candidate_index = scores_N.max(dim=0)\n",
    "\n",
    "        candidate_indices.append(candidate_index.item())\n",
    "        candidate_scores.append(candidate_score.item())\n",
    "\n",
    "    return CandidateBatch(candidate_scores, candidate_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a8da19",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "863e4aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234917, 0.05961958627158337, 0.08691070514744714, 0.11275304532467878], indices=[0, 3, 1, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batchbald_batch(ys_ws.log().double(), 4, 1000, dtype=torch.double)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3575566",
   "metadata": {},
   "source": [
    "## Batch BALD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d2b7abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BaldSelectorFunction(log_probs_N_K_C: torch.Tensor, \n",
    "                         batch_size: int) -> CandidateBatch:\n",
    "    \n",
    "    ### Set Up ###\n",
    "    UncertaintyMetrics = []   \n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "    Indices = []\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "\n",
    "    ### Compute Uncertainty Metrics ###\n",
    "    EnsembleEntropy = ComputeEntropyFunction(log_probs_N_K_C)\n",
    "    ConditionalEntropy = ComputeConditionalEntropyFunction(log_probs_N_K_C)\n",
    "    UncertaintyMetrics = EnsembleEntropy - ConditionalEntropy\n",
    "\n",
    "    ### Get Top Scores ###\n",
    "    UncertaintyMetrics, Indices = torch.topk(UncertaintyMetrics, batch_size)\n",
    "\n",
    "    return CandidateBatch(UncertaintyMetrics.tolist(), Indices.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bce20f",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6131b7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.030715639666234917]\n",
      "[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "BatchBaldResults = BaldSelectorFunction(ys_ws.log().double(), 1)\n",
    "print(BatchBaldResults.scores)\n",
    "print(BatchBaldResults.indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
